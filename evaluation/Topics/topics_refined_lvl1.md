[1] Automated Program Repair (Count: 32): Techniques that automatically generate patches or refactorings to fix bugs or performance faults in software.
[1] Security Patch Detection (Count: 5): Techniques for identifying and classifying security patches in software repositories using multi-modal data (commit messages, code changes, developer activity, CVE references) to aid vulnerability management and patch prioritization.
[1] Code Summarization (Count: 9): Generating high-level descriptions of code repositories by aggregating segment-level summaries and grounding in domain context for business applications, enabling improved code understanding and maintenance.
[1] Code Generation (Count: 50): Automatic creation or augmentation of source code using AI/LLMs, including evaluation of correctness, performance, and energy efficiency.
[1] Vulnerability Scoring (Count: 3): Automated assessment and scoring of software vulnerabilities (e.g., CVSS) using machine learning and generative AI to predict vector metrics and overall severity, with emphasis on data quality and standardized vulnerability descriptions.
[1] Code Vulnerability Analysis (Count: 7): The study of identifying, localizing, reasoning about, and mitigating vulnerabilities in source code, including an emphasis on structure and semantic reasoning, data-flow and control-flow analysis, and vulnerability-focused evaluation of models.
[1] Code Security Benchmarking (Count: 6): The development and use of benchmarks and datasets to evaluate code security tasks (identification, repair, safe-generation, QA, and reasoning) for LLMs and automated tools.
[1] Large Language Models for Code Security (Count: 8): The application and evaluation of large language models in software security tasks, addressing trustworthiness, robustness, and genuine reasoning beyond pattern matching in vulnerability analysis.
[1] Benchmark Data Contamination Mitigation (Count: 2): General strategies to prevent data leakage and benchmark contamination in evaluation of Code LLMs, including semantic-preserving code perturbations, cross-file dependency preservation, multi-language support, and verification of perturbations.
[1] Fault Localization (Count: 5): Identifying faulty components or code regions responsible for observed failures.
[1] Code Optimization (Count: 8): Automated improvement of source code performance (time, memory, energy) while preserving functionality, using automated methods (e.g., ML-based optimization, diffs, patches) to generate minimal changes.
[1] Program Synthesis (Count: 18): Automated generation of programs or code from specifications, leveraging search, ML, and interactive disambiguation to satisfy user intent.
[1] LLM Reasoning and Rationale Generation (Count: 18): Automates the generation and refinement of step-by-step thinking processes (rationales) for large language models, using a probabilistic graphical model, reinforcement learning, and evaluation signals to improve reasoning performance across tasks such as math and coding benchmarks.
[1] Cybersecurity Benchmarking for LLMs (Count: 5): Frameworks, datasets, and evaluation methods for assessing large language models in cybersecurity contexts, including knowledge extraction, understanding, and reasoning, with emphasis on Industrial Control Systems.
[1] Algorithmic Problem Solving (Count: 2): General techniques for solving programming contest problems, including problem formulation, counting strategies, and efficient implementations.
[1] Code Understanding and Graph Extraction (Count: 5): Techniques to understand software behavior and extract interpretable causal graphs/diagrams from code using AST, data-flow analysis, and LLMs.
[1] Automated Code Review (Count: 2): Automating the code review process using AI/LLMs and rule-based pipelines to detect issues, generate review comments, and continuously improve through data-driven feedback mechanisms at scale.
